{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ebe263b-c44e-484d-a56b-73951bf05c3d",
   "metadata": {},
   "source": [
    "# Intro to PyTorch\n",
    "\n",
    "So far we have manually been working with weights, biases, activation functions, and plugging in inputs. What you may have noticed is that there is a pattern to these operations with neural networks. Essentially these neural net operations are a series of matrix operations. With the rise in popularity of NN's and machine learning several libraries emerged to provide large matrix operation support and various ML functions.\n",
    "\n",
    "TensorFlow and PyTorch are the most popular with recent years seeing PyTorch grow as the go to ML framework. PyTorch has support for tensors (multi-dimensional matricies), NN construction, working with datasets, and learning processes. We will play around with some of the building blocks of PyTorch before we put it all together and make our own NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36af1d-6d7a-45b7-9fbe-e29266ece93d",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "Tensors are the building blocks of most actions in PyTorch, our data will be represented as tensors, our weights can be tensors, they are very important. You'll likely spending a lot of time initially playing with the dimensionality of your tensors to have them match a target shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690efd6-db55-4937-9859-fae487d39bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Lets represent a series of 2D points as a tensor to start\n",
    "points = torch.tensor([[1, 2], [2, 3], [4, 5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79c954-0106-4019-b36c-410209204f8a",
   "metadata": {},
   "source": [
    "\"Shape\" tells us how our tensor is layed out, this becomes very important when we start to apply operations on our tensors because operations between tensors require their shape to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e0fe5-5ae0-4d9c-8d17-7cac8259c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6f0e5-9d11-41cf-85cf-c4c886e6d1a7",
   "metadata": {},
   "source": [
    "This tells us that we have a tensor that is 3x2 in shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bccae6-ffaa-42ac-96cc-931a10e43af9",
   "metadata": {},
   "source": [
    "Tensors in PyTorch operate very similarly to numpy arrays and intend there is good compatibility between the two. As with numpy we can perform operations on PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9e3a9-5627-4ba4-88c8-27298fe2ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d45548-e437-4ac1-8d36-dc7041047be6",
   "metadata": {},
   "source": [
    "What about things like images? Well we could represent a color image by a C-by-H-by-W where \"C\" are the number of color channels, \"H\" is the height and \"W\" is the width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0ee0b-0515-4005-b9c6-3d909d7835e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import decode_image\n",
    "\n",
    "img = decode_image('../data/street_view.png')\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0d557-d896-45c4-af21-b2b65946fb8e",
   "metadata": {},
   "source": [
    "However, sometimes we want to represent images in different formats. For example, OpenCV has images in the format H-W-C. We can use PyTorch's permute operation and convert directly to numpy if we need to perform OpenCV operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a390f3-7cd4-410a-861c-b0ae2e50762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "opencv_img = img.permute((1, 2, 0))\n",
    "\n",
    "plt.imshow(opencv_img)\n",
    "opencv_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b3811-6419-4b0a-843d-c4ae1c3c7f6f",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Another set of useful PyTorch operations presented is the ability to work with \"Datasets\". PyTorch \"datasets\" are groups of data with useful operations around. You can make your own datasets or use built in PyTorch datasets.\n",
    "\n",
    "Built in PyTorch Datasets: https://docs.pytorch.org/vision/stable/datasets.html\n",
    "\n",
    "The code below will help us download one of the existing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c44fb-1ac8-4061-abff-bbb8bb708a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "flower_set = datasets.Flowers102('../data', download=True, split='test', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747b8ea-be0a-40a6-b555-e30741d37232",
   "metadata": {},
   "source": [
    "Now what we can do is use a data loader to specify how to read in the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73e0b4-5971-4595-9877-5051d046bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(flower_set)\n",
    "\n",
    "image, label = next(iter(dataloader))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f93619-e8ca-4d8f-905b-b01dfd7d00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[0].permute((1, 2, 0)))\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5a8b9c-a7ce-4927-828e-61bcae0a5f4f",
   "metadata": {},
   "source": [
    "## Neural Network Layers\n",
    "\n",
    "PyTorch also provides a lot of functionalty around making layers for your neural network. A \"layer\" is essentally a series of of neurons in a configuration you define. It makes it much easier to work with NNs with potentially millions of neurons. Below is an example with a linear makeup of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e7e2e-e00e-41b7-ba56-f3883bfe4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input data\n",
    "input_data = torch.tensor([[0.0, 1.0, 2.0]])\n",
    "\n",
    "# Making the layer\n",
    "layer = torch.nn.Linear(3, 1)\n",
    "\n",
    "# Providing the weights and bias\n",
    "layer.weight = torch.nn.Parameter(torch.tensor([[3.0, 4.0, 5.0]]))\n",
    "layer.bias = torch.nn.Parameter(torch.tensor([3.0]))\n",
    "\n",
    "# Pass the input through the layer\n",
    "layer(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29798b65-3f2a-4350-b453-f78d8cb90f34",
   "metadata": {},
   "source": [
    "Layers can then easily feed into each other (as long as the shapes of the tensors match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00da60-7c4b-483b-aed7-5d64ee4b0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.tensor([[0.0, 1.0, 2.0]])\n",
    "\n",
    "layer1 = torch.nn.Linear(3, 2)\n",
    "layer1.weight = torch.nn.Parameter(torch.tensor([[3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]))\n",
    "layer1.bias = torch.nn.Parameter(torch.tensor([3.0, 4.0]))\n",
    "\n",
    "layer2 = torch.nn.Linear(2, 1)\n",
    "layer2.weight = torch.nn.Parameter(torch.tensor([[1.0, 2.0]]))\n",
    "layer2.bias = torch.nn.Parameter(torch.tensor([5.0]))\n",
    "\n",
    "x = layer1(input_data)\n",
    "x = layer2(x)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e690631-742a-4976-9280-272956c10b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1\n",
    "(0 * 3 + 1 * 4 + 2 * 5) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b96d26a-017a-4a98-b3b5-8e6fcc314378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 2\n",
    "(0 * 6 + 1 * 7 + 2 * 8) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d060518-297a-4ff1-b44f-132ec1da3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 3\n",
    "(17 * 1 + 27 * 2) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f52a069-6c83-40f0-a5d0-e90813bf6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.tensor([[\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0]\n",
    "]])\n",
    "\n",
    "conv = torch.nn.Conv2d(1, 2, 1, bias=False)\n",
    "conv.weight = torch.nn.Parameter(torch.tensor([[[[6.0]]], [[[7.0]]]]))\n",
    "\n",
    "conv(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee18fdc-b83e-4e56-88b8-d74c3128aa46",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "PyTorch also has built in loss functions (as well as optimizers that can use that loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afdf5a8-4005-4798-bb27-1d44004297e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = torch.Tensor([5, 6, 7])\n",
    "expected_output = torch.Tensor([5, 7, 8])\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "loss_fn(model_output, expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0babd52b-71c1-49a3-be31-67a9cb6ec52f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
