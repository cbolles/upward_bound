{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac8c4004-f8f2-4e38-a301-88b8b6d94331",
   "metadata": {},
   "source": [
    "# MNIST Dataset\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We've now talked about why we need machine learning (some relationships are too complex to represent manually), we've looked at the different components of machine learning (model, parameters, loss functions, optimizers), implementing machine learning in a small scale application (linear regression with stochastic gradient descent), and how PyTorch gives us the tools to have more power over our machine learning. Now we are going to combine all of those ideas together to write a model which will identify hand written numbers for us.\n",
    "\n",
    "### The Dataset\n",
    "\n",
    "The MNIST dataset is a curated set of hand written numbers that is commonly used as a starting point for machine learning. The original dataset created by NIST (National Institute for Standards and Technology) was leveraged in various goverment tasks related to OCR (Optical Character Recognition). Think tasks like reading tax forms, postal addresses, other manual entry processes. MNIST is a subset of the dataset selected to be more ideal for machine learning with a more sophisticated test/training split. The dataset includes 60,000 images in the training set and 10,000 images in the test set.\n",
    "\n",
    "### CNNs\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a special kind of neural network designed for learning features what can assist in recognizing patterns in typically grid like data. They are inspired by how perception works in the brain, but like all neural networks are a simplifaction.\n",
    "\n",
    "If we remember back to the template matching at the begining, for template matching to work, we need a good starting template. CNNs provide us a way to learn more complex features. Interestingly CNNs still effectivly apply a template matching like algorithm, but leveraging machine learning to learn the templates for us.\n",
    "\n",
    "#### AlexNet\n",
    "\n",
    "CNNs for object detection have been on of the widest applications of machine learning (before LLMs). AlexNet is a CNN developed at the University of Toronto to detect up to 1,000 distinct objects and is often times a starting point for making for specifically tuned CNNs since the heavy lifting of training a lot of the parameters has been taken care of by the team.\n",
    "\n",
    "* For more information on the MNIST dataset: https://en.wikipedia.org/wiki/MNIST_database\n",
    "* MNIST CNN Visualizer: https://adamharley.com/nn_vis/\n",
    "* GoogLeNet Visualizer: https://distill.pub/2017/feature-visualization/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e579c-d1ee-4d07-bda3-071cc38fbbea",
   "metadata": {},
   "source": [
    "## Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51155b-3e64-4679-b85d-259f2b3209ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Using PyTorch's built in data for MNIST, we are telling it to download the training set\n",
    "train_set = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# The data loader then specifies how we can load in the downloaded images into Python\n",
    "dataloader = torch.utils.data.DataLoader(train_set, batch_size=10)\n",
    "\n",
    "# Function to display images taken from https://pythonguides.com/pytorch-mnist/\n",
    "def show_images(images, labels):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(10):\n",
    "        axes[i].imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "        axes[i].set_title(f\"Label: {labels[i]}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Now we will pull out 10 images to look at\n",
    "images, labels = next(iter(dataloader))\n",
    "\n",
    "# Show images\n",
    "show_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea591f1b-31e7-40b6-8fac-4755c55aa24b",
   "metadata": {},
   "source": [
    "## Creating the Model Structure\n",
    "\n",
    "PyTorch comes with several layers/operations that will be really helpful fo us to build our NN.\n",
    "\n",
    "Model being leveraged: https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
    "\n",
    "* Conv2D: https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "\n",
    "  Allows the for creating a convolution layer. The layer needs a few pieces of information.\n",
    "  1. How many channels are coming in. This usually refers to things like colors in normal RGB images (which would be 3 channels)\n",
    "  2. How many output channels, which will essentially be the number of different filters we will learn\n",
    "  3. The size of each filter\n",
    "* Dropout: https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n",
    "\n",
    "  Lets us randomly \"ignore\" certain neurons. This is helpful to reduce the chance that the neurons learn features that are too similar or overfit. This only takes place during training\n",
    "* Linear: https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "  Apply an affine linear transformation\n",
    "* ReLu: https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
    "\n",
    "  Activation function where the result is evaluated as the max(0, result from the neuron)\n",
    "* Max Pooling: https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
    "\n",
    "  Provides a way to shrink the feature set into a smaller representation\n",
    "\n",
    "* Log Soft Max: https://docs.pytorch.org/docs/2.8/generated/torch.nn.LogSoftmax.html\n",
    "* Feature Visualization: https://kushmadlani.github.io/visualising-cnn-layers/\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934fe41-9d62-494c-9a48-b2bf05f74d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # First convolution layer will have a single channel\n",
    "        # the result will be 32 filters that will be learned\n",
    "        # with each filter being a 3x3 kernel\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "\n",
    "        # Second convolution layer that will take in the 32\n",
    "        # filtered results and produce 64 filters with\n",
    "        # each filter being a 3x3 kernel\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "\n",
    "        # One of the dropout operations we want to learn\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        # A second dropout that is at a higher probability\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # First linear layer that will take 9216 features down to 128\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "\n",
    "        # Second linear layer that will take 128 features down to 10\n",
    "        # This is very important because this represents the number \n",
    "        # of outputs (the digits 0 - 9)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First take the image and pass it through our first\n",
    "        # convolution layer\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # Next apply the relu activation function\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Now pass the resulting filtered image through the\n",
    "        # second convolution layer\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # Apply another relu activation function\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Down sample the resulting image following\n",
    "        # a 2x2 max pool\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Apply a drop out to reduce chance of \n",
    "        # over fitting\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # We still have out data in a 2D format, but the output\n",
    "        # is 1 dimensional (0 - 9). Flatten will make a single\n",
    "        # dimensional input\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Now that we have a 1D input, we can start to learn how to\n",
    "        # turn our larger vector of features into a detection of\n",
    "        # the digits 0-9\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        # Use relu as the activation function again\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Apply the second drop out to again try to \n",
    "        # reduce the chance of overfitting\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # The final linear layer that will bring down the features\n",
    "        # to 10 in total\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Finally we apply this log softmax\n",
    "        # Soft max creates essentially a probabily \n",
    "        # distribution. We can think of it as \"how likley is the input to be a given digit\"\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f218926-ba97-4fae-825f-5496daaaae63",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We have now defined our model, the parameters will start with default values that are typically based on a probability function. So if we go back to our representation of the machine learning at this point we having the following.\n",
    "\n",
    "* [x] Model: The Python class that inherets from PyTorch's neural network module \n",
    "* [x] Parameters: Initialized following probabiliy function, ready to be trained\n",
    "* [ ] Loss Function: TBD\n",
    "* [ ] Optimizer: TBD\n",
    "\n",
    "### Understanding the Model Output\n",
    "\n",
    "For this case, we are doing that is typically considered a \"Classification\" problem. We have some input, and we are trying to decide what \"class\" it belongs to (digits 0 - 9). The way we figure out what the model thinks the input is is by looking at the output tensor of our model. The output tensor dimension is a 1 dimensional tensor with 10 elements. We apply what is called the `log_softmax` to smooth out the output. Lets take the steps manually to get a sense of what the output is so we can understand what loss function will work for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f1cf48-580d-48ad-9080-b28b49d23f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start with some tensor to represent the output from the model before our softmax is applied\n",
    "detection_results = torch.tensor([1.0, 250.0, 2.0, 300.0, 45.0, 6.0, 1.0, 2.5, 8.6, 10.0], dtype=torch.float32)\n",
    "\n",
    "# Soft max results\n",
    "torch.nn.functional.softmax(detection_results, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca75a79-846c-4503-a83c-20f15eeb8a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Soft Max Results\n",
    "torch.nn.functional.log_softmax(detection_results, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a4967e-3fd9-479f-8529-fcdabd481574",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "Since we are working with probability distributions, we can leverage the negative log-likelihood loss function. The negative log likelihood function essentially provides us a way to figure out how likely the output is based on the known distribution.\n",
    "\n",
    "https://towardsdatascience.com/cross-entropy-negative-log-likelihood-and-all-that-jazz-47a95bd2e81/\n",
    "\n",
    "### Optimizer\n",
    "\n",
    "For the optimizer, we will use Adadelta. Adadelta is based on stochastic gradient descent, but the learning rate it self is updated as the learning takes place. This makes it a bit easier to train without having the guess-and-check the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0387c42-fefe-44c6-b55d-9e732aa8202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Make sure our train and test sets are downloaded\n",
    "train_data = datasets.MNIST(\n",
    "    root='../data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='../data',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Setup the data loaders, we will load in 100 images per batch\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1)\n",
    "\n",
    "# The device is used for hardware acceleration, basically we can have the training run on the CPU or GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# We now make an instance of our model, it will have default parameters\n",
    "model = CustomCNN().to(device)\n",
    "\n",
    "# Creating the optimizer, the initial learning rate we set fairly high, but it will adjust as the learning is run\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "\n",
    "# The train function itself, we have it as a function to make it easier to train for multiple \"epoches\".\n",
    "# An \"epoch\" is a pass over all of the data. \n",
    "def train(epoch):\n",
    "    # Put the model into train mode. This tells the model helpful things like if the parameters should\n",
    "    # be fixed or if they are being trained on, also in train mode dropout layers actually apply\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # We need the data to live on the same device as the model (either CPU or GPU)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Now we basically see what the output is for the given input\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate the loss based on the known value, remember our data loader includes\n",
    "        # both the image and the known label\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        # Updated the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # Periodically (ever 100 batches) print some statistics. This isn't doing any ML work\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "\n",
    "# The test function is then used to determine\n",
    "def test():\n",
    "    # Put the model into eval mode. The parameters will be fixed and the dropout layers won't actually\n",
    "    # do any drop out.\n",
    "    model.eval()\n",
    "\n",
    "    # These are some variables for us to capture statistics on model performance\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # No grad means no gradient, since we are evaluating and not training we don't need\n",
    "    # to calculate the gradient. This is a memory saving step\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # Just as before, reading in data and moving it to either the CPU or GPU\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Running the image through the model\n",
    "            output = model(data)\n",
    "\n",
    "            # Compute the loss, this is so we can see how close to the answer we are\n",
    "            test_loss += F.nll_loss(output, target).item()\n",
    "\n",
    "            # Remember that the max value represents that the model things the answer is, \n",
    "            # so we can figure out what the prediction is\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            # We then can keep track of the number of correct answer\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    # Finally print out some statistics\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss: 0.4f}, Accuracy {correct}/{len(test_loader.dataset)}  ({100 * correct / len(test_loader.dataset):.0f}%)\\n\")\n",
    "\n",
    "# We will run for 10 epoches, each time going through the whole dataset\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e60dd3-f6f4-4a7e-b759-bceb04a50d3b",
   "metadata": {},
   "source": [
    "## After Training\n",
    "\n",
    "### Saving the Model\n",
    "\n",
    "Yay! We now have a trained model! Now what? Well first we probably don't want to have to train the model each time we want to use it. What we can do is save the output of the model.\n",
    "\n",
    "Remember that a model is the structure and the parameters represent the specific solution learned. Therefore what we will need to do is save the parameters so we can load them again. PyTorch makes this pretty easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39be77-19e3-4568-ab79-fff647666a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), '../data/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca020fb-04f7-41d8-a485-dd382852f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "new_model = CustomCNN()\n",
    "new_model.load_state_dict(torch.load('../data/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d766d-75c2-42a3-bd53-5682d12085d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also see what the state dictionary is capturing\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e29fc-51e4-4954-a93a-3781bb1f7f13",
   "metadata": {},
   "source": [
    "### Using the Model\n",
    "\n",
    "Great! But we've made this model so that we can actually use it. Lets take a very basic example and see how it performs on a set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b326129-8921-4e84-a1d4-7a95bc31bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Using PyTorch's built in data for MNIST, we are telling it to download the training set\n",
    "train_set = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# The data loader then specifies how we can load in the downloaded images into Python\n",
    "dataloader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "\n",
    "# Function to display images taken from https://pythonguides.com/pytorch-mnist/\n",
    "def show_images(images, labels, pred):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(10):\n",
    "        axes[i].imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "        axes[i].set_title(f\"Label: {labels[i]}, \\n Prediction: {pred[i][0]}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Now we will pull out 10 images to look at\n",
    "images, labels = next(iter(dataloader))\n",
    "\n",
    "# Lets now run the model on the images to get the predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(images.to(device))\n",
    "    pred = outputs.argmax(dim=1, keepdim=True).to('cpu')\n",
    "\n",
    "# Show images\n",
    "show_images(images, labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d97a1-e9fe-4158-bbd6-1d6d489d2c1f",
   "metadata": {},
   "source": [
    "## Visualizing Filters\n",
    "\n",
    "We can work through the feature representation to an extend.\n",
    "We will start with the work here: https://kushmadlani.github.io/visualising-cnn-layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0cf87-8bdb-4b14-a8e9-8347844b1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "def get_activations(name):\n",
    "    \"\"\"Create hook function for layer given\"\"\"\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model = model.to('cpu')\n",
    "model.conv1.register_forward_hook(get_activations(\"conv1\"))\n",
    "model.conv2.register_forward_hook(get_activations(\"conv2\"))\n",
    "\n",
    "train_dataloader_full = torch.utils.data.DataLoader(train_set, \n",
    "                                                    batch_size=len(train_set),\n",
    "                                                    shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "avgOriginals = torch.zeros((10,1,28,28))\n",
    "avgAct = torch.zeros((10, 64, 24, 24))\n",
    "imgs, labels = next(iter(train_dataloader_full))\n",
    "for digit in range(0, 10):\n",
    "    idx = (labels==digit).nonzero().squeeze()\n",
    "    data = imgs[idx]\n",
    "    avgOriginals[digit] = data.sum(0)\n",
    "    output = model(data)\n",
    "    avgAct[digit] = F.relu(activations[\"conv2\"]).sum(0)\n",
    "data = avgOriginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a3f6d-dd93-4b5c-9cff-f7c073e900e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showActivations(data, activations, plot_size=(20,7), same_scale=False):\n",
    "    \"\"\"Plot feature map for each example digit\"\"\"\n",
    "    fig, axarr = plt.subplots(activations.size(0), activations.size(1)+1, figsize=plot_size)\n",
    "\n",
    "    # extract max/min values to scale\n",
    "    if same_scale: \n",
    "        vmin = activations.min()\n",
    "        vmax = activations.max() \n",
    "\n",
    "    for digit in range(activations.size(0)):\n",
    "        # show original images\n",
    "        axarr[digit, 0].imshow(data[digit,0], cmap='gray')\n",
    "        axarr[digit, 0].set_xticks([])\n",
    "        axarr[digit, 0].set_yticks([])\n",
    "        axarr[digit, 0].set_ylabel(f'{digit}')\n",
    "\n",
    "        # show features\n",
    "        for feature in range(activations.size(1)):\n",
    "            if same_scale: \n",
    "              axarr[digit, feature+1].imshow(activations[digit, feature], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "            else: \n",
    "              axarr[digit, feature+1].imshow(activations[digit, feature], cmap='gray')\n",
    "            axarr[digit, feature+1].set_xticks([])\n",
    "            axarr[digit, feature+1].set_yticks([])\n",
    "            if digit == 0:\n",
    "                axarr[digit, feature+1].set_title(\"Feature \"+str(feature+1))\n",
    "\n",
    "showActivations(data, avgAct, plot_size=(20,15), same_scale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3c427-99b1-45da-9de7-2071abea7814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
