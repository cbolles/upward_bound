{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190471d6-b737-4cb7-a81b-1d3dd31bb3bc",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "So far we've looked at linear models in the context of machine learning. But how do we get to the object detection example from the begining? We will need a system that allows for non-linear computation as well as capturing more complex relationships like the spatial relationships the pixels have that make up shapes.\n",
    "\n",
    "That is where neural networks come in. Neural networks are a classification of ML models inspired by biological neural connections. Neural networks are made up of a series of linear and non-linear operations combined together in a network like structure to essentailly transform an input into an output.\n",
    "\n",
    "<< go over structure of a neuron on the board >>\n",
    "\n",
    "* Neuron: Single node in a neural network\n",
    "* Weights: One weight per input applied via multiplication\n",
    "* Bias: Constant applied after summing over weights and inputs\n",
    "* Activation Function: Function (non-linear or linear) applied to the linear sum of our weights, inputs, and bias\n",
    "\n",
    "$$output = f((\\Sigma_{i=0}^n w_i * x_i) + b) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8d0da-a213-4a5c-b643-b1316d16abd5",
   "metadata": {},
   "source": [
    "We can implement a neuron ourselves with some realtive simplistic code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ea21c-2254-41f2-a6d8-a24887cef14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from collections.abc import Callable\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights: npt.ArrayLike, bias: float, activation_function: Callable[[float], float]):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def apply(self, inputs: npt.ArrayLike) -> float:\n",
    "        # Perform element-wise multiplication and sum\n",
    "        sum_weights = np.sum(np.multiply(inputs, self.weights))\n",
    "\n",
    "        # Add the bias\n",
    "        total = sum_weights + self.bias\n",
    "\n",
    "        # Apply the activiation function\n",
    "        result = self.activation_function(total)\n",
    "\n",
    "        # Now return the final result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590c5da-70d5-464f-a27e-daf5ba0b91d7",
   "metadata": {},
   "source": [
    "Lets see how we can use a neuron to replicate the linear function $y = 5x + 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199878a-8821-4110-9692-dbc2e89c4352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function which doesn't modify the value passed in\n",
    "def no_action(num: float) -> float:\n",
    "    return num\n",
    "\n",
    "# One input so only one weight and a bias of 10\n",
    "linear_neuron = Neuron(np.array([5]), 10, no_action)\n",
    "\n",
    "# Now lets try plotting some values\n",
    "x = np.arange(10)\n",
    "y = np.vectorize(linear_neuron.apply)(x)\n",
    "\n",
    "plt.plot(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a23892-c6c8-40aa-9890-8a6e4372c43f",
   "metadata": {},
   "source": [
    "Now lets look at an example where we have multiple input dimensions. Something like the house estimator where we will consider square footage and number of bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd473a91-3641-47e8-b0a0-c83edd070c8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "house_estimate = Neuron(np.array([500, 10000]), 65000, no_action)\n",
    "# Now lets try plotting some values\n",
    "x = np.column_stack([np.linspace(500, 7_000, 10), np.linspace(1, 10, 10)])\n",
    "y = [house_estimate.apply(i) for i in x]\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(x[:, 0], x[:, 1], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6639d3a5-6f5e-4222-88dd-35ba0d806e8b",
   "metadata": {},
   "source": [
    "So far we have been manually putting in weights and biases into our neurons. But ultimately we will get to the point of having these weights learned for us via our machine learning algorithm. Also right now we only have a single neuron, but real world applications have millions or billions of neurons combined together to produce complex relationships.\n",
    "\n",
    "Having multiple hidden layers in a neural network together we refer to as \"Deep Learning\" and has become nearly the default format of machine learning in recent years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2644240-fd1f-4adb-9355-1c4b8c74960c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
