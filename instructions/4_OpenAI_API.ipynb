{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49bf00be-a8de-4e56-b8b8-8261c22c7529",
   "metadata": {},
   "source": [
    "# Section 4 OpenAI API\n",
    "\n",
    "Now that we know a bit of Python, how to communicate across the internet, and how to pull data, let's see how we can interface with one of the biggest names in AI at the moment OpenAI.\n",
    "\n",
    "OpenAI is the company which has brought us tools like ChatGPT and DALL-E. They provide something called an \"API\" which allows us to interact with their services through code. API stands for \"application programming interface\" and is basically a documented way to talk with a service. OpenAI provides an API to interact with most of their tools which we will play around with.\n",
    "\n",
    "OpenAI provides [a ton of documentation](https://platform.openai.com/docs/introduction) on using their APIs. You'll find examples for making the requests manually (like we did in the previous section) or using one of their libraries for Python or Javascript. We will make use of their Python library for interacting with their API.\n",
    "\n",
    "Below is a basic example of using the OpenAI API to generate an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a760f54-1bff-4d53-8451-9a33115c64c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (0.27.4)\n",
      "Requirement already satisfied: aiohttp in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: tqdm in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/cbolles/devel/sail/upward-bound/venv/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d9504-0120-48af-9823-fca2c9e27f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from IPython import display\n",
    "from base64 import b64decode\n",
    "\n",
    "# First I'm going to get the API key. The key is what we use to \"login\" to OpenAI\n",
    "key = 'INSERT_KEY_HERE'\n",
    "\n",
    "\n",
    "# Next I'll setup the OpenAI library with my credentials\n",
    "openai.api_key = key\n",
    "\n",
    "# Now I can make the request to generate the image. All I did was follow OpenAI's documentation\n",
    "# https://platform.openai.com/docs/guides/images/usage\n",
    "response = openai.Image.create(\n",
    "    prompt='a boston terrier in a red sweater',\n",
    "    n=1,\n",
    "    size='512x512',\n",
    "    response_format='b64_json'\n",
    ")\n",
    "\n",
    "\n",
    "# The response gives us a lot of information back, I'm going to grab the data that represent the image\n",
    "image_data = response['data'][0]['b64_json']\n",
    "display.Image(b64decode(image_data))\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2cd83-4239-41f9-a95d-808656fdd2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
